from snakemake.utils import min_version
min_version("6.9.1")

# This pipeline takes a list of species names
# as input and downloads the corresponding genome
# assemblies where available. It then creates
# a multi-species fasta file and a table linking
# the taxon ids, genbank accession number and 
# species for all the sequences in the fasta file.

# Note that the resource usage for building indexes
# should be adjusted depending on the fasta file size

# Run as:
# snakemake -c 1 -s Snakefile_make_assm_db --use-singularity
#

# Make rulegraph with:
# snakemake -c 1 -s Snakefile_make_assm_db --dag | dot -Tsvg > DAG_make_assm_db.svg

# List of species to download (one per line)
SPECIES ="target_species_with_related_n65.txt"		

rule all:
	input:
		"target_species.1.bt2l",
		"taxon_table.csv",
		"clean_done.txt"

# Download genbank assembly summary table
rule genbank_table:
	output:
		"gbk_summary/assembly_summary_genbank.txt"
	shell:
		"""
		wget https://ftp.ncbi.nlm.nih.gov/genomes/genbank/assembly_summary_genbank.txt
		mv assembly_summary_genbank.txt {output[0]}
		"""

# Make a summary table for target
# genomes
rule target_species:
	input:
		SPECIES,
		"gbk_summary/assembly_summary_genbank.txt"
	output:
		"assembly_summary_target_species.txt"
	shell:
		"""
		bash make_summary_table.sh {input[0]} {input[1]} {output[0]}
		"""

# Make a script with paths to download genomes
# with wget. Use '-nc' so no download if the file
# exists.
rule make_ftp_script:
	input:
		"assembly_summary_target_species.txt",
	output:
		temp("ftp_paths.txt"),
		"run_ftp_downloads.sh"
	shell:
		"""
		cut -f20 {input[0]} > {output[0]}
		awk 'BEGIN{{FS=OFS="/";filesuffix="genomic.fna.gz"}}\
			{{ftpdir=$0;asm=$10;file=asm"_"filesuffix;dir=$10;print \
			"wget -nc "ftpdir,file" -P "asm"/"}}'\
			{output[0]} > {output[1]}
		"""

# Download genomes
rule download_genomes:
	input:
		"run_ftp_downloads.sh"
	output:
		"download_log.txt"
	shell:
		"""
		bash {input[0]} 2> {output}
		"""

# Combine genomes
rule cat_genomes:
	input:
		"download_log.txt"
	output:
		"target_species.fasta"
	params:
		temp_out = "temp.fasta.gz"
	shell:
		"""
		cat GCA_*/*.gz > {params.temp_out}
		gunzip {params.temp_out}
		mv temp.fasta {output[0]}
		"""

rule get_headers:
	input:
		"target_species.fasta"
	output:
		"seq_ids.txt"
	shell:
		"""
		grep '>' {input[0]} | sed 's/>//' >> {output[0]}
		"""

# Note - Use fat node and all cores
rule bowtie_idx:
	input:
		"target_species.fasta"
	output:
		"target_species.1.bt2l",
		"target_species.2.bt2l",
		"target_species.3.bt2l",
		"target_species.4.bt2l",
		"target_species.rev.1.bt2l",
		"target_species.rev.2.bt2l"
	params:
		idx_base = "target_species"
	threads: 16
	container: "https://depot.galaxyproject.org/singularity/bowtie2:2.4.5--py39hd2f7db1_3"
	shell:
		"""
		bowtie2-build --large-index --threads {threads} {input[0]} {params.idx_base}
		"""

# Make a table with contig,species,taxid
rule make_taxon_table:
	input:
		"assembly_summary_target_species.txt",
		"seq_ids.txt"
	output:
		"taxon_table.csv"
	shell:
		"""
		module load python/3.7.2
		python make_id_table_with_taxid.py {input[0]} {input[1]} {output[0]}
		"""

# Cleanup fastas
rule clean:
	input:
		"seq_ids.txt"
	output:
		"clean_done.txt"
	shell:
		"""
		rm -r GCA_*/
		head -n 0 {input[0]} >> {output[0]} 
		"""
